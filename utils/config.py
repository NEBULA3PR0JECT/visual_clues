config = {
    'blip_model_url_base': 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_retrieval_coco.pth',
    'blip_vit_base': 'base',
    'blip_model_url_large': '/inputs/blipitc-checkpoint/model_large_retrieval_coco.pth', 
    'blip_vit_large': 'large',
    'blip_image_size': 384,
    'clip_checkpoints': "openai/clip-vit-base-patch32",
    'caption_model_ckpt_ofa': 'ckpt/finetuned/caption_huge_best.pt',
    'ofa_bpe_path': 'utils/BPE'
}

#'blip_model_url_large': 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_retrieval_coco.pth'