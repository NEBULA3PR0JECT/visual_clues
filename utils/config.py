config = {
    'blip_model_url_base': 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_retrieval_coco.pth',
    'blip_vit_base': 'base',
    'blip_model_url_large': 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_retrieval_coco.pth',
    'blip_vit_large': 'large',
    'blip_image_size': 384,
    'clip_checkpoints': "openai/clip-vit-base-patch32"
}